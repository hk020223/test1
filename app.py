import streamlit as st
import pandas as pd
import os
import glob
import datetime
import json
from langchain_community.document_loaders import PyPDFLoader
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate

# -----------------------------------------------------------------------------
# [0] ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (ì´ˆê³ ì† ëª¨ë“œ ì ìš©)
# -----------------------------------------------------------------------------
st.set_page_config(page_title="KW-ê°•ì˜ë§ˆìŠ¤í„° Pro", page_icon="ğŸ“", layout="wide")
api_key = os.environ.get("GOOGLE_API_KEY", "")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "global_log" not in st.session_state:
    st.session_state.global_log = [] 
if "timetable_result" not in st.session_state:
    st.session_state.timetable_result = "" 
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [] 
if "current_menu" not in st.session_state:
    st.session_state.current_menu = "ğŸ¤– AI í•™ì‚¬ ì§€ì‹ì¸"
if "timetable_chat_history" not in st.session_state:
    st.session_state.timetable_chat_history = []

def add_log(role, content, menu_context=None):
    timestamp = datetime.datetime.now().strftime("%H:%M")
    st.session_state.global_log.append({
        "role": role,
        "content": content,
        "time": timestamp,
        "menu": menu_context
    })

# ê°€ìƒ ê°•ì˜í‰ ë°ì´í„°
def load_mock_reviews():
    data = {
        "ê³¼ëª©ëª…": ["Cí”„ë¡œê·¸ë˜ë°", "Cí”„ë¡œê·¸ë˜ë°", "ëŒ€í•™ìˆ˜í•™1", "ê³µí•™ì„¤ê³„ì…ë¬¸", "ëŒ€í•™ì˜ì–´", "íšŒë¡œì´ë¡ 1", "ëŒ€í•™ë¬¼ë¦¬í•™1"],
        "êµìˆ˜ëª…": ["ê¹€ì½”ë”©", "ì´ìë°”", "ì´ìˆ˜í•™", "ë°•ì„¤ê³„", "Brown", "ìµœì „ê¸°", "ë‚˜ë¬¼ë¦¬"],
        "ê°•ì˜í‰": [
            "ê³¼ì œ í­íƒ„ì…ë‹ˆë‹¤. ì‚´ë ¤ì£¼ì„¸ìš”.",
            "ì²œì‚¬ êµìˆ˜ë‹˜. í•™ì  ì˜ ì£¼ì‹¬.",
            "ì§„ë„ê°€ ë„ˆë¬´ ë¹ ë¦„. ì˜ˆìŠµ í•„ìˆ˜.",
            "íŒ€í”Œ ë¹ŒëŸ° ë§Œë‚˜ë©´ í•œ í•™ê¸° ë§í•¨.",
            "ì¶œì„ë§Œ ì˜ í•˜ë©´ B+ì€ ê¸°ë³¸.",
            "ì‹œí—˜ì´ ì¡±ë³´ì—ì„œ ê·¸ëŒ€ë¡œ ë‚˜ì˜´.",
            "ë¬¼í¬ìë„ ì´í•´í•˜ê²Œ ì„¤ëª…í•´ì£¼ì‹¬."
        ],
        "ì‹œí—˜ì •ë³´": [
            "ì†ì½”ë”© ì‹œí—˜", "ì‹¤ìŠµ ì‹œí—˜", "êµì¬ ì—°ìŠµë¬¸ì œ ë³€í˜•", "ë°œí‘œ ë¹„ì¤‘ í¼", "ì˜¤í”ˆë¶", "ì¡±ë³´ ì•”ê¸° í•„ìˆ˜", "ê³µì‹ ì•”ê¸° ìœ„ì£¼"
        ]
    }
    return pd.DataFrame(data)

REVIEW_DB = load_mock_reviews()

@st.cache_resource(show_spinner=False)
def load_knowledge_base():
    """
    [ì´ˆê³ ì† ë¡œë”©] ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” í…ìŠ¤íŠ¸ íŒŒì¼(cached_knowledge.txt)ì„ ìš°ì„ ì ìœ¼ë¡œ ì½ìŠµë‹ˆë‹¤.
    """
    cache_file = "data/cached_knowledge.txt"
    
    # 1. ë¯¸ë¦¬ í•™ìŠµëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸ (ê°€ì¥ ë¹ ë¦„)
    if os.path.exists(cache_file):
        try:
            with open(cache_file, "r", encoding="utf-8") as f:
                data = f.read()
                if len(data) > 10: # ë‚´ìš©ì´ ì œëŒ€ë¡œ ìˆëŠ”ì§€ í™•ì¸
                    return data, True # True = ìºì‹œ ì‚¬ìš©ë¨
        except:
            pass # ì½ê¸° ì‹¤íŒ¨í•˜ë©´ ì•„ë˜ë¡œ ë„˜ì–´ê°

    # 2. ìºì‹œê°€ ì—†ìœ¼ë©´ PDF ì§ì ‘ íŒŒì‹± (ëŠë¦¼, ë¹„ìƒìš©)
    if not os.path.exists("data"):
        return "", False
        
    all_content = ""
    pdf_files = glob.glob("data/*.pdf")
    if not pdf_files:
        return "", False
        
    for pdf_file in pdf_files:
        try:
            loader = PyPDFLoader(pdf_file)
            pages = loader.load_and_split()
            filename = os.path.basename(pdf_file)
            all_content += f"\n\n--- [ë¬¸ì„œ: {filename}] ---\n"
            for page in pages:
                all_content += page.page_content
        except: continue
    
    return all_content, False # False = ì‹¤ì‹œê°„ íŒŒì‹±ë¨

# ë°ì´í„° ë¡œë“œ ì‹¤í–‰
PRE_LEARNED_DATA, IS_CACHED = load_knowledge_base()

# ë¡œë”© ìƒíƒœ í‘œì‹œ (ì‚¬ì´ë“œë°”)
if IS_CACHED:
    # í† ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” ì•± ì¼¤ ë•Œ í•œ ë²ˆë§Œ ì“± ì§€ë‚˜ê°
    st.toast("âš¡ ë¯¸ë¦¬ í•™ìŠµëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¦‰ì‹œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="ğŸš€")

# -----------------------------------------------------------------------------
# [1] AI ì—”ì§„
# -----------------------------------------------------------------------------
def get_llm():
    if not api_key: return None
    return ChatGoogleGenerativeAI(model="gemini-2.5-flash-preview-09-2025", temperature=0)

def ask_ai(question):
    llm = get_llm()
    if not llm: return "âš ï¸ API Key ì˜¤ë¥˜"
    try:
        chain = PromptTemplate.from_template(
            "ë¬¸ì„œ ë‚´ìš©: {context}\nì§ˆë¬¸: {question}\në¬¸ì„œì— ê¸°ë°˜í•´ ë‹µë³€í•´ì¤˜."
        ) | llm
        return chain.invoke({"context": PRE_LEARNED_DATA, "question": question}).content
    except Exception as e: return str(e)

# ì‹œê°„í‘œ ìƒì„± í•¨ìˆ˜ (HTML ì»¬ëŸ¬ í…Œì´ë¸” + ì„ ìˆ˜ê³¼ëª© ê°•ì¡°)
def generate_timetable_ai(major, grade, semester, target_credits, blocked_times_desc, requirements):
    llm = get_llm()
    if not llm: return "âš ï¸ API Key ì˜¤ë¥˜"
    
    review_summary = REVIEW_DB.to_string()
    
    template = """
    ë„ˆëŠ” ëŒ€í•™êµ ìˆ˜ê°•ì‹ ì²­ ì „ë¬¸ê°€ì•¼. PDF ë¬¸ì„œ(ì‹œê°„í‘œ, ìš”ëŒ)ë¥¼ ë¶„ì„í•´ì„œ ìµœì ì˜ ì‹œê°„í‘œë¥¼ ì§œì¤˜.

    [í•™ìƒ ì •ë³´]
    - {major} {grade} {semester}
    - ëª©í‘œ: {target_credits}í•™ì 
    - ê³µê°• í•„ìˆ˜ ì‹œê°„: {blocked_times} (ì´ ì‹œê°„ì€ ìˆ˜ì—… ë°°ì¹˜ ì ˆëŒ€ ê¸ˆì§€)
    - ì¶”ê°€ìš”êµ¬: {requirements}

    [ê°•ì˜í‰ ë°ì´í„°]
    {review_data}

    [í•„ìˆ˜ ì§€ì‹œì‚¬í•­]
    1. **ëª¨ë“  í•™ë…„ì˜ ì„ ìˆ˜/í›„ìˆ˜ ê³¼ëª© ì² ì € ì¤€ìˆ˜**:
       - 1í•™ë…„ë¿ë§Œ ì•„ë‹ˆë¼, **2, 3, 4í•™ë…„ì˜ ì „ê³µ ì—°ê³„ì„±**ì„ ë°˜ë“œì‹œ í™•ì¸í•´ë¼.
       - ì˜ˆì‹œ: "íšŒë¡œì´ë¡ 1(1í•™ê¸°) â†’ íšŒë¡œì´ë¡ 2(2í•™ê¸°)", "ì „ìì¥1 â†’ ì „ìì¥2", "ì¢…í•©ì„¤ê³„(ìº¡ìŠ¤í†¤) ì´ìˆ˜ ì¡°ê±´" ë“±.
       - í•´ë‹¹ í•™ê¸°({semester})ì— ë“¤ì–´ì•¼ ë‹¤ìŒ í•™ê¸°ë‚˜ ë‹¤ìŒ í•™ë…„ì— ë¬¸ì œê°€ ì—†ëŠ” **'í•„ìˆ˜ ì„ ìˆ˜ ê³¼ëª©'**ì€ ë¬´ì¡°ê±´ ì‹œê°„í‘œì— ë„£ì–´ë¼.
       - ê²°ê³¼ ì„¤ëª…ì— "**[í•„ìˆ˜] ì´ ê³¼ëª©ì€ ë‹¤ìŒ ë‹¨ê³„ì¸ OOê³¼ëª© ìˆ˜ê°•ì„ ìœ„í•´ ê¼­ ë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.**"ë¼ê³  ì´ìœ ë¥¼ ëª…ì‹œí•´ë¼.
    
    2. **ì¶œë ¥ í˜•ì‹ (HTML Table)**:
       - ë§ˆí¬ë‹¤ìš´ í‘œ ëŒ€ì‹  **HTML `<table>` íƒœê·¸**ë¥¼ ì‚¬ìš©í•´ë¼.
       - ê° ìˆ˜ì—…ë§ˆë‹¤ **ì„œë¡œ ë‹¤ë¥¸ íŒŒìŠ¤í…”í†¤ ë°°ê²½ìƒ‰**(`style="background-color: #..."`)ì„ ì ìš©í•´ë¼.
       - ì…€ ë‚´ìš©: `<b>ê³¼ëª©ëª…</b><br><small>êµìˆ˜ëª…</small>`
       - í–‰: 1êµì‹œ~9êµì‹œ (ì‹œê°„ ë¯¸í¬í•¨), ì—´: ì›”~ê¸ˆ
       - í‘œëŠ” ì‹œê°ì ìœ¼ë¡œ ì˜ˆì˜ê³  ê¹”ë”í•˜ê²Œ ë§Œë“¤ì–´ë¼.
    
    3. **ê³µê°• ì‹œê°„ ì²˜ë¦¬**:
       - ê³µê°•ìœ¼ë¡œ ì§€ì •ëœ ì‹œê°„ì€ ë¹„ì›Œë‘¬ë¼.
       - ì¶œë ¥ ì‹œ "ê³µê°• í•„ìˆ˜ ì‹œê°„" ëª©ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì£¼ì§€ ë§ˆë¼. (ê²°ê³¼ë¬¼ë§Œ ê¹”ë”í•˜ê²Œ)

    [í•™ìŠµëœ ë¬¸ì„œ]
    {context}
    """
    prompt = PromptTemplate(template=template, input_variables=["context", "major", "grade", "semester", "target_credits", "blocked_times", "requirements", "review_data"])
    chain = prompt | llm
    input_data = {
        "context": PRE_LEARNED_DATA,
        "major": major,
        "grade": grade,
        "semester": semester,
        "target_credits": target_credits,
        "blocked_times": blocked_times_desc,
        "requirements": requirements,
        "review_data": review_summary
    }
    return chain.invoke(input_data).content

def chat_with_timetable_ai(current_timetable, user_input):
    llm = get_llm()
    template = """
    ë„ˆëŠ” í˜„ì¬ ì‹œê°„í‘œì— ëŒ€í•œ ìƒë‹´ì„ í•´ì£¼ëŠ” AI ì¡°êµì•¼.
    
    [í˜„ì¬ ì‹œê°„í‘œ ìƒíƒœ]
    {current_timetable}

    [ì‚¬ìš©ì ì…ë ¥]
    "{user_input}"

    [ì§€ì‹œì‚¬í•­]
    ì‚¬ìš©ìì˜ ì…ë ¥ ì˜ë„ë¥¼ íŒŒì•…í•´ì„œ ì•„ë˜ ë‘ ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë°˜ì‘í•´.
    
    **Case 1. ì‹œê°„í‘œ ìˆ˜ì • ìš”ì²­ì¸ ê²½ìš° (ì˜ˆ: "1êµì‹œ ë¹¼ì¤˜", "êµìˆ˜ ë°”ê¿”ì¤˜"):**
    - ì‹œê°„í‘œë¥¼ **ì¬ì‘ì„±(HTML Table í˜•ì‹ ìœ ì§€)**í•´ì¤˜.
    - ìˆ˜ì •ëœ ì‹œê°„í‘œë¥¼ ì¶œë ¥í•˜ê³ , ë¬´ì—‡ì´ ë°”ë€Œì—ˆëŠ”ì§€ ì§§ê²Œ ì„¤ëª…í•´.
    
    **Case 2. ê³¼ëª©ì— ëŒ€í•œ ë‹¨ìˆœ ì§ˆë¬¸ì¸ ê²½ìš° (ì˜ˆ: "Cí”„ë¡œê·¸ë˜ë° ê³¼ì œ ë§ì•„?", "ì´ê±° ì„ ìˆ˜ê³¼ëª© ë­ì•¼?"):**
    - **ì‹œê°„í‘œë¥¼ ë‹¤ì‹œ ì¶œë ¥í•˜ì§€ ë§ê³ **, ì§ˆë¬¸ì— ëŒ€í•œ **í…ìŠ¤íŠ¸ ë‹µë³€**ë§Œ í•´.
    - ê°•ì˜í‰ ë°ì´í„°ë‚˜ í•™ìŠµëœ ì§€ì‹ì„ í™œìš©í•´.
    
    ë‹µë³€ ì‹œì‘ì— [ìˆ˜ì •] ë˜ëŠ” [ë‹µë³€] íƒœê·¸ë¥¼ ë¶™ì—¬ì„œ êµ¬ë¶„í•´ì¤˜.
    """
    prompt = PromptTemplate(template=template, input_variables=["current_timetable", "user_input"])
    chain = prompt | llm
    return chain.invoke({"current_timetable": current_timetable, "user_input": user_input}).content

# -----------------------------------------------------------------------------
# [2] UI êµ¬ì„±
# -----------------------------------------------------------------------------
def change_menu(menu_name):
    st.session_state.current_menu = menu_name

with st.sidebar:
    st.title("ğŸ—‚ï¸ í™œë™ ë¡œê·¸")
    st.caption("í´ë¦­í•˜ë©´ í•´ë‹¹ í™”ë©´ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
    
    log_container = st.container(height=400)
    with log_container:
        if not st.session_state.global_log:
            st.info("ê¸°ë¡ ì—†ìŒ")
        else:
            for i, log in enumerate(reversed(st.session_state.global_log)):
                label = f"[{log['time']}] {log['content'][:15]}..."
                if st.button(label, key=f"log_btn_{i}", use_container_width=True):
                    if log['menu']:
                        change_menu(log['menu'])
                        st.rerun()

    st.divider()
    st.markdown("### â„¹ï¸ ìƒíƒœ")
    if IS_CACHED:
        st.success("ğŸš€ ê³ ì† ëª¨ë“œ (Pre-learned)")
    elif PRE_LEARNED_DATA:
        st.warning("ğŸ¢ ì¼ë°˜ ëª¨ë“œ (PDF ì‹¤ì‹œê°„ ë¶„ì„)")
    else:
        st.error("ë°ì´í„° ì—†ìŒ")


menu = st.radio("ê¸°ëŠ¥ ì„ íƒ", ["ğŸ¤– AI í•™ì‚¬ ì§€ì‹ì¸", "ğŸ“… ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ(ìˆ˜ì •ê°€ëŠ¥)", "ğŸ” ê°•ì˜í‰ ë¶„ì„"], 
                horizontal=True, key="menu_radio", 
                index=["ğŸ¤– AI í•™ì‚¬ ì§€ì‹ì¸", "ğŸ“… ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ(ìˆ˜ì •ê°€ëŠ¥)", "ğŸ” ê°•ì˜í‰ ë¶„ì„"].index(st.session_state.current_menu))

if menu != st.session_state.current_menu:
    st.session_state.current_menu = menu
    st.rerun()

st.divider()

if st.session_state.current_menu == "ğŸ¤– AI í•™ì‚¬ ì§€ì‹ì¸":
    st.subheader("ğŸ¤– ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”")
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if user_input := st.chat_input("ì§ˆë¬¸ ì…ë ¥"):
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        add_log("user", f"[ì§€ì‹ì¸] {user_input}", "ğŸ¤– AI í•™ì‚¬ ì§€ì‹ì¸")
        with st.chat_message("user"):
            st.markdown(user_input)
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                response = ask_ai(user_input)
                st.markdown(response)
        st.session_state.chat_history.append({"role": "assistant", "content": response})

elif st.session_state.current_menu == "ğŸ“… ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ(ìˆ˜ì •ê°€ëŠ¥)":
    st.subheader("ğŸ“… AI ë§ì¶¤í˜• ì‹œê°„í‘œ ì„¤ê³„")

    if st.session_state.timetable_result:
        st.markdown("### ğŸ—“ï¸ ë‚´ ì‹œê°„í‘œ")
        st.markdown(st.session_state.timetable_result, unsafe_allow_html=True)
        st.divider()

    with st.expander("ì‹œê°„í‘œ ì„¤ì • ì—´ê¸°/ë‹«ê¸°", expanded=not bool(st.session_state.timetable_result)):
        col1, col2 = st.columns([1, 1.5])
        with col1:
            st.markdown("#### 1ï¸âƒ£ ê¸°ë³¸ ì •ë³´")
            major = st.text_input("í•™ê³¼", "ì „ììœµí•©ê³µí•™ê³¼")
            c1, c2 = st.columns(2)
            grade = c1.selectbox("í•™ë…„", ["1í•™ë…„", "2í•™ë…„", "3í•™ë…„", "4í•™ë…„"])
            semester = c2.selectbox("í•™ê¸°", ["1í•™ê¸°", "2í•™ê¸°"])
            target_credit = st.number_input("ëª©í‘œ í•™ì ", 9, 24, 18)
            requirements = st.text_area("ì¶”ê°€ ìš”êµ¬ì‚¬í•­", placeholder="ì˜ˆ: ì „ê³µ í•„ìˆ˜ ì±™ê²¨ì¤˜")

        with col2:
            st.markdown("#### 2ï¸âƒ£ ê³µê°• ì‹œê°„ ì„¤ì •")
            kw_times = {
                "1êµì‹œ": "09:00~10:15", "2êµì‹œ": "10:30~11:45", "3êµì‹œ": "12:00~13:15",
                "4êµì‹œ": "13:30~14:45", "5êµì‹œ": "15:00~16:15", "6êµì‹œ": "16:30~17:45",
                "7êµì‹œ": "18:00~19:15", "8êµì‹œ": "19:25~20:40", "9êµì‹œ": "20:50~22:05"
            }
            schedule_index = [f"{k} ({v})" for k, v in kw_times.items()]
            schedule_data = pd.DataFrame(True, index=schedule_index, columns=["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ"])
            edited_schedule = st.data_editor(
                schedule_data,
                column_config={
                    "ì›”": st.column_config.CheckboxColumn("ì›”", default=True),
                    "í™”": st.column_config.CheckboxColumn("í™”", default=True),
                    "ìˆ˜": st.column_config.CheckboxColumn("ìˆ˜", default=True),
                    "ëª©": st.column_config.CheckboxColumn("ëª©", default=True),
                    "ê¸ˆ": st.column_config.CheckboxColumn("ê¸ˆ", default=True),
                },
                height=360,
                use_container_width=True
            )

        if st.button("ì‹œê°„í‘œ ìƒì„±í•˜ê¸° âœ¨", type="primary", use_container_width=True):
            blocked_times = []
            for day in ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ"]:
                for idx, period_label in enumerate(edited_schedule.index):
                    if not edited_schedule.iloc[idx][day]:
                        blocked_times.append(f"{day}ìš”ì¼ {period_label}")
            blocked_desc = ", ".join(blocked_times) if blocked_times else "ì—†ìŒ"
            with st.spinner("ì„ ìˆ˜ê³¼ëª© í™•ì¸ ë° ì‹œê°„í‘œ ì¡°í•© ì¤‘..."):
                result = generate_timetable_ai(major, grade, semester, target_credit, blocked_desc, requirements)
                st.session_state.timetable_result = result
                st.session_state.timetable_chat_history = []
                add_log("user", f"[ì‹œê°„í‘œ] {major} {grade} ìƒì„±", "ğŸ“… ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ(ìˆ˜ì •ê°€ëŠ¥)")
                st.rerun()

    if st.session_state.timetable_result:
        st.subheader("ğŸ’¬ ì‹œê°„í‘œ ìƒë‹´ì†Œ")
        st.caption("ì‹œê°„í‘œì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜(Q&A), ìˆ˜ì •ì„ ìš”ì²­(Refine)í•˜ì„¸ìš”.")
        for msg in st.session_state.timetable_chat_history:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"], unsafe_allow_html=True)

        if chat_input := st.chat_input("ì˜ˆ: 1êµì‹œ ë¹¼ì¤˜, ë˜ëŠ” ëŒ€í•™ìˆ˜í•™1 ê¼­ ë“¤ì–´ì•¼ í•´?"):
            st.session_state.timetable_chat_history.append({"role": "user", "content": chat_input})
            add_log("user", f"[ìƒë‹´] {chat_input}", "ğŸ“… ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ(ìˆ˜ì •ê°€ëŠ¥)")
            with st.chat_message("user"):
                st.write(chat_input)
            with st.chat_message("assistant"):
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    response = chat_with_timetable_ai(st.session_state.timetable_result, chat_input)
                    if "[ìˆ˜ì •]" in response:
                        new_timetable = response.replace("[ìˆ˜ì •]", "").strip()
                        st.session_state.timetable_result = new_timetable
                        st.markdown(new_timetable, unsafe_allow_html=True)
                        st.session_state.timetable_chat_history.append({"role": "assistant", "content": "ì‹œê°„í‘œë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. ìœ„ìª½ í‘œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."})
                        st.rerun()
                    else:
                        clean_response = response.replace("[ë‹µë³€]", "").strip()
                        st.markdown(clean_response)
                        st.session_state.timetable_chat_history.append({"role": "assistant", "content": clean_response})

elif st.session_state.current_menu == "ğŸ” ê°•ì˜í‰ ë¶„ì„":
    st.subheader("ğŸ” ê°•ì˜í‰ íŒ©íŠ¸ì²´í¬")
    col1, col2 = st.columns(2)
    c_name = col1.selectbox("ê³¼ëª©ëª…", REVIEW_DB['ê³¼ëª©ëª…'].unique())
    p_name = col2.selectbox("êµìˆ˜ëª…", REVIEW_DB[REVIEW_DB['ê³¼ëª©ëª…'] == c_name]['êµìˆ˜ëª…'].unique())
    
    if "review_chat" not in st.session_state:
        st.session_state.review_chat = []

    if st.button("ë¶„ì„ ì‹œì‘"):
        reviews = REVIEW_DB[(REVIEW_DB['ê³¼ëª©ëª…']==c_name) & (REVIEW_DB['êµìˆ˜ëª…']==p_name)]
        context = reviews.to_string()
        prompt = f"ê³¼ëª©: {c_name}, êµìˆ˜: {p_name}\në°ì´í„°: {context}\nì´ ê°•ì˜ì˜ ì¥ë‹¨ì ê³¼ ì‹œí—˜ ìŠ¤íƒ€ì¼ì„ ìš”ì•½í•´ì¤˜."
        with st.spinner("ë¶„ì„ ì¤‘..."):
            llm = get_llm()
            res = llm.invoke(prompt).content
            st.session_state.review_chat = [{"role": "assistant", "content": res, "context": context}]
            add_log("user", f"[ê°•ì˜í‰] {c_name}", "ğŸ” ê°•ì˜í‰ ë¶„ì„")

    for msg in st.session_state.review_chat:
        if "role" in msg:
            with st.chat_message(msg["role"]):
                st.write(msg["content"])

    if st.session_state.review_chat:
        if q_input := st.chat_input("ì§ˆë¬¸ ì…ë ¥"):
            st.session_state.review_chat.append({"role": "user", "content": q_input})
            with st.chat_message("user"):
                st.write(q_input)
            with st.chat_message("assistant"):
                context_data = st.session_state.review_chat[0].get("context", "")
                llm = get_llm()
                ans = llm.invoke(f"ë°ì´í„°: {context_data}\nì§ˆë¬¸: {q_input}\në‹µë³€í•´.").content
                st.write(ans)
                st.session_state.review_chat.append({"role": "assistant", "content": ans})
